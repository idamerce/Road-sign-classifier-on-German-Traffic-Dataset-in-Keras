{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_only_to_run",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp5UcZD69zBKv9joCFPtWT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/idamerce/Road-sign-classifier-on-German-Traffic-Dataset-in-Keras/blob/master/pytorchmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxDIbH3ytWWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10  # Maximum sentence length\n",
        "\n",
        "# Default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwTKCHccvAeo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "        keep_words = []\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)\n",
        "\n",
        "\n",
        "# Lowercase and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "# Takes string sentence, returns sentence of word indexes\n",
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGR6B1cbvAbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # type: (Tensor, Tensor, Optional[Tensor]) -> Tuple[Tensor, Tensor]\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR1lHsJR5SJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfwv3bnn5WK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TorchScript Notes:\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~\n",
        "#\n",
        "# Similarly to the ``EncoderRNN``, this module does not contain any\n",
        "# data-dependent control flow. Therefore, we can once again use\n",
        "# **tracing** to convert this model to TorchScript after it\n",
        "# is initialized and its parameters are loaded.\n",
        "#\n",
        "\n",
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_uXy1yy9whg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, decoder_n_layers):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self._device = device\n",
        "        self._SOS_token = SOS_token\n",
        "        self._decoder_n_layers = decoder_n_layers\n",
        "\n",
        "    __constants__ = ['_device', '_SOS_token', '_decoder_n_layers']\n",
        "\n",
        "    def forward(self, input_seq : torch.Tensor, input_length : torch.Tensor, max_length : int):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, 1, device=self._device, dtype=torch.long) * self._SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=self._device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ZrjFpO899m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31631fe5-004e-46ad-f217-56cbd1939012"
      },
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "corpus_name = \"cornell movie-dialogs corpus\"\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "#attn_model = 'general'\n",
        "#attn_model = 'concat'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# If you're loading your own model\n",
        "# Set checkpoint to load from\n",
        "checkpoint_iter = 4000\n",
        "# loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "#                             '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "#                             '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "# If you're loading the hosted model\n",
        "loadFilename = '/content/4000_checkpoint.tar'\n",
        "\n",
        "# Load model\n",
        "# Force CPU device options (to match tensors in this tutorial)\n",
        "checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
        "encoder_sd = checkpoint['en']\n",
        "decoder_sd = checkpoint['de']\n",
        "encoder_optimizer_sd = checkpoint['en_opt']\n",
        "decoder_optimizer_sd = checkpoint['de_opt']\n",
        "embedding_sd = checkpoint['embedding']\n",
        "voc = Voc(corpus_name)\n",
        "voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Load trained model params\n",
        "encoder.load_state_dict(encoder_sd)\n",
        "decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Set dropout layers to eval mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "print('Models built and ready to go!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP7SE-u7YRQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gtts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OnoByFLO7Uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "\n",
        "\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio  \n",
        "\n",
        "\n",
        "\n",
        "# Evaluate inputs from user input (stdin)\n",
        "def evaluateInput(searcher, voc,input_sentence):\n",
        "    #input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            #input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            #if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            engine = gTTS(''.join(output_words))  \n",
        "            engine.save('a1.wav') \n",
        "            Audio('a1.wav', autoplay=True)  \n",
        "            print('Bot:', ' '.join(output_words))\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate inputs from user input (stdin)\n",
        "def evaluateInput2(searcher, voc):\n",
        "  input_sentence = ''\n",
        "  try:\n",
        "    # Get input sentence\n",
        "    input_sentence = input('> ')\n",
        "    # Check if it is quit case\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(input_sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words = evaluate(searcher, voc, input_sentence)\n",
        "    # Format and print response sentence\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))\n",
        "    bot_answer=' '.join(output_words)\n",
        "    engine = gTTS(''+bot_answer)  \n",
        "    engine.save('a1.wav') \n",
        "  except KeyError:\n",
        "    print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Normalize input sentence and call evaluate()\n",
        "def evaluateExample(sentence, searcher, voc):\n",
        "    print(\"> \" + sentence)\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words = evaluate(searcher, voc, input_sentence)\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erEtYvKr6TdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder,decoder_n_layers)\n",
        "#evaluateInput2(searcher,voc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QwY6jcoesLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a7cced28-c1f7-430c-d2ed-cabea4046eed"
      },
      "source": [
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio \n",
        "input_sentence = ''\n",
        "try:\n",
        "  input_sentence = input('> ')\n",
        "  input_sentence = normalizeString(input_sentence)\n",
        "  output_words = evaluate(searcher, voc, input_sentence)\n",
        "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "  print('Bot:', ' '.join(output_words))\n",
        "  bot_answer=' '.join(output_words)\n",
        "  engine = gTTS(''+bot_answer)  \n",
        "  engine.save('a1.wav')\n",
        "except:\n",
        "  erreur=\"Sorry, i did not understand you ,Please change the way you say it\"\n",
        "  print(\"\"+erreur)\n",
        "  engine = gTTS(''+bot_answer)  \n",
        "  engine.save('a1.wav')\n",
        "Audio('a1.wav', autoplay=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> hi\n",
            "Bot: hi .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su2ypxJ4Xmpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pTSlvlrXq6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhQgLlBgbfYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6sk8DybbeME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmUr4dXe7MQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "2c8a886a-8fe0-4a95-b740-64554dedf222"
      },
      "source": [
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio \n",
        "import speech_recognition as spechrec\n",
        "import scipy\n",
        "import random \n",
        "\n",
        "\n",
        "input_sentence = ''\n",
        "try:\n",
        "  audio, sr=get_audio()\n",
        "  scipy.io.wavfile.write('recording.wav', sr, audio)\n",
        "  r = spechrec.Recognizer()\n",
        "  with spechrec.AudioFile(\"recording.wav\") as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)\n",
        "  input_sentence=text\n",
        "  input_sentence = normalizeString(input_sentence)\n",
        "  output_words = evaluate(searcher, voc, input_sentence)\n",
        "  output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "  print('Bot:', ' '.join(output_words))\n",
        "  bot_answer=' '.join(output_words)\n",
        "  engine = gTTS(''+bot_answer) \n",
        " \n",
        "  engine.save('a1.wav')\n",
        "  Audio('a1.wav', autoplay=True) \n",
        "except:\n",
        "  erreur = random.choice([\"Sorry, i did not understand you ,Please change the way you say it\",\n",
        "                 \"please be a little simple in your discussion i m not a human\",\n",
        "                 \"Sorry, get in mind  that you are talking only with a computer \"])\n",
        "  print(\"\"+erreur)\n",
        "  engine = gTTS(''+erreur)  \n",
        "  engine.save('a1.wav')\n",
        "Audio('a1.wav', autoplay=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "your help please\n",
            "Bot: i m not wasting my life !\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZScKp88h_GV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "accd7951-2e35-49ba-bee1-f5dbe6cf3dab"
      },
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "  return audio, sr\n",
        "print(\"get_audio is now defined\")\n",
        "#audio, sr=get_audio()\n",
        "#import scipy\n",
        "#scipy.io.wavfile.write('recording.wav', sr, audio)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "get_audio is now defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvhwCOq3h_Dc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import speech_recognition as spechrec\n",
        "filename = \"recording.wav\"\n",
        "r = spechrec.Recognizer()\n",
        "with spechrec.AudioFile(filename) as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkYndh9xddcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fByX5Qwbddqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDXO4ANaddmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO run had lcommands befor you start the runtime bax ydownloadi lik 4000_checkpoint.tar flocal "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd8NdSES7MKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "92799c06-472f-46a2-b006-59caa283b83b"
      },
      "source": [
        "!wget \"https://download.pytorch.org/models/tutorials/4000_checkpoint.tar\" "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 19:50:48--  https://download.pytorch.org/models/tutorials/4000_checkpoint.tar\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.226.45.35, 13.226.45.16, 13.226.45.86, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.226.45.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257811088 (246M) [application/x-tar]\n",
            "Saving to: 4000_checkpoint.tar\n",
            "\n",
            "4000_checkpoint.tar 100%[===================>] 245.87M  64.8MB/s    in 3.9s    \n",
            "\n",
            "2020-07-15 19:50:52 (63.7 MB/s) - 4000_checkpoint.tar saved [257811088/257811088]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH8vEb4eYJ01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZTWf7mDvVPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4927caa2-1e5c-4729-f77c-5c11c72c5b77"
      },
      "source": [
        "!pip3 install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.6/dist-packages (3.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W_LIHsWvVMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "!pip install pyaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsT20b6wvVJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cImHcSC6vVGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gtts"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}